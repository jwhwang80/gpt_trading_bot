import os
import asyncio
import pandas as pd
from binance.client import Client
from datetime import datetime, timedelta, timezone
import time

api_key = os.environ.get('BINANCE_TEST_API_KEY')
api_secret = os.environ.get('BINANCE_TEST_API_SECRET')

SYMBOL = "BTCUSDT"
DAYS = 3000
CSV_FILE = f"{SYMBOL}_1m_{DAYS}day_data.csv"  # 1ë¶„ë´‰ìœ¼ë¡œ ë³€ê²½
MAX_RETRIES = 3


async def fetch_historical_chart(client, symbol, start_time, end_time, interval):
    """Binanceì—ì„œ 1ë¶„ë´‰ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ì˜ˆì™¸ ì²˜ë¦¬ í¬í•¨)"""

    for attempt in range(1, MAX_RETRIES + 1):
        try:
            klines = client.get_historical_klines(
                symbol,
                interval,
                start_time.strftime("%Y-%m-%d %H:%M:%S"),
                end_time.strftime("%Y-%m-%d %H:%M:%S")
            )

            if not klines:
                print(f"âš ï¸ ë°ì´í„° ì—†ìŒ: {start_time} ~ {end_time}")
                return []

            data = [
                [
                    datetime.fromtimestamp(kline[0] / 1000, tz=timezone.utc),  # timestamp
                    float(kline[1]),  # Open
                    float(kline[2]),  # High
                    float(kline[3]),  # Low
                    float(kline[4]),  # Close
                    float(kline[5])  # Volume
                ]
                for kline in klines
            ]

            # ğŸ”¥ ìµœì‹  ì‹œê°„ì´ ì²« ë²ˆì§¸ê°€ ë˜ë„ë¡ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
            data.sort(reverse=True, key=lambda x: x[0])

            return data

        except Exception as e:
            print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ (ì‹œë„ {attempt}/{MAX_RETRIES}): {e}")
            if "Too many requests" in str(e):
                print("â³ API ì œí•œìœ¼ë¡œ 10ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                time.sleep(10)  # Binance ì†ë„ ì œí•œ ì‹œ ëŒ€ê¸°
            else:
                time.sleep(2)  # ì¼ë°˜ì ì¸ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œ 2ì´ˆ ëŒ€ê¸°

    print(f"âŒ {start_time} ~ {end_time} ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨. ìŠ¤í‚µí•¨.")
    return []


async def main():
    client = Client(api_key, api_secret, {"timeout": 5})

    # CSV íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    file_exists = os.path.exists(CSV_FILE)
    all_data = []

    # í˜„ì¬ ì‹œê°„
    current_time = datetime.now(timezone.utc)

    # íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ê°€ì¥ ìµœê·¼ ë°ì´í„°ì˜ ì‹œê°„ì„ ê°€ì ¸ì™€ì„œ ì‹œì‘ ì‹œê°„ìœ¼ë¡œ ì„¤ì •
    if file_exists:
        try:
            existing_df = pd.read_csv(CSV_FILE)
            if not existing_df.empty:
                # 'Time' ì—´ì„ datetimeìœ¼ë¡œ ë³€í™˜
                existing_df['Time'] = pd.to_datetime(existing_df['Time'])

                # ê°€ì¥ ìµœê·¼ ì‹œê°„ ì°¾ê¸° (ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬ëœ ê²½ìš° ì²« ë²ˆì§¸ í–‰)
                latest_time = existing_df['Time'].max()

                # ì‹œì‘ ì‹œê°„ì„ ê°€ì¥ ìµœê·¼ ë°ì´í„° ì´í›„ë¡œ ì„¤ì • (1ë¶„ ì¶”ê°€)
                start_time = pd.to_datetime(latest_time).to_pydatetime().replace(tzinfo=timezone.utc) + timedelta(
                    minutes=1)

                print(f"ğŸ“ˆ ê¸°ì¡´ ë°ì´í„°ì˜ ë§ˆì§€ë§‰ ì‹œê°„: {latest_time}")
                print(f"ğŸ”„ {start_time}ë¶€í„° í˜„ì¬ê¹Œì§€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.")
            else:
                print("âš ï¸ ê¸°ì¡´ íŒŒì¼ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì „ì²´ ê¸°ê°„ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.")
                start_time = current_time - timedelta(days=DAYS)
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            start_time = current_time - timedelta(days=DAYS)
    else:
        print("âš ï¸ ê¸°ì¡´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ê¸°ê°„ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.")
        start_time = current_time - timedelta(days=DAYS)

    # ë§Œì•½ ì‹œì‘ ì‹œê°„ì´ í˜„ì¬ ì‹œê°„ë³´ë‹¤ ì´í›„ë¼ë©´, ì´ë¯¸ ìµœì‹  ìƒíƒœ
    if start_time >= current_time:
        print("âœ… ë°ì´í„°ê°€ ì´ë¯¸ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤.")
        return

    # API í˜¸ì¶œ ì‹œê°„ ì œí•œì„ ê³ ë ¤í•˜ì—¬ í•˜ë£¨ ë‹¨ìœ„ë¡œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    # 1ë¶„ë´‰ì€ 5ë¶„ë´‰ë³´ë‹¤ ë°ì´í„° ì–‘ì´ ë§ìœ¼ë¯€ë¡œ ë” ì§§ì€ ê¸°ê°„ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤
    delta = timedelta(hours=12)  # 12ì‹œê°„ ë‹¨ìœ„ë¡œ ë³€ê²½

    # ì‹œì‘ ì‹œê°„ë¶€í„° í˜„ì¬ ì‹œê°„ê¹Œì§€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    end_time = current_time
    chunk_start_time = start_time

    while chunk_start_time < end_time:
        # ì²­í¬ ì¢…ë£Œ ì‹œê°„ ê³„ì‚°
        chunk_end_time = chunk_start_time + delta
        if chunk_end_time > end_time:
            chunk_end_time = end_time

        print(f"ğŸ“¡ Fetching data from {chunk_start_time} to {chunk_end_time}...")

        data = await fetch_historical_chart(client, SYMBOL, chunk_start_time, chunk_end_time,
                                            Client.KLINE_INTERVAL_1MINUTE)

        if data:
            all_data.extend(data)  # ì •ë ¬ëœ ë°ì´í„° ì¶”ê°€
            print(f"âœ… {len(data)}ê°œ ë°ì´í„° ì €ì¥ ì™„ë£Œ.")
        else:
            print(f"âš ï¸ {chunk_start_time} ~ {chunk_end_time} ë°ì´í„° ì—†ìŒ. ë‹¤ìŒìœ¼ë¡œ ì§„í–‰.")

        # ë‹¤ìŒ ì²­í¬ì˜ ì‹œì‘ ì‹œê°„ ì—…ë°ì´íŠ¸
        chunk_start_time = chunk_end_time

        # API ì œí•œ ë°©ì§€ë¥¼ ìœ„í•´ ëŒ€ê¸°
        await asyncio.sleep(1)

    if all_data:
        df = pd.DataFrame(all_data, columns=["Time", "Open", "High", "Low", "Close", "Volume"])

        # CSVë¡œ ì €ì¥ (ê¸°ì¡´ íŒŒì¼ì´ ìˆë‹¤ë©´ ì¶”ê°€)
        if file_exists:
            # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆ ë°ì´í„°ë¥¼ í•©ì¹˜ê³  ì¤‘ë³µ ì œê±°
            existing_df = pd.read_csv(CSV_FILE)
            existing_df['Time'] = pd.to_datetime(existing_df['Time'])

            # ìƒˆ ë°ì´í„°í”„ë ˆì„ í•©ì¹˜ê¸°
            combined_df = pd.concat([existing_df, df])

            # ì¤‘ë³µ ì œê±°í•˜ê³  ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            combined_df = combined_df.drop_duplicates(subset=['Time']).sort_values(by="Time", ascending=False)

            # ìµœì¢… ë°ì´í„°í”„ë ˆì„ ì €ì¥
            combined_df.to_csv(CSV_FILE, index=False)
            print(f"ğŸ“‚ ì´ {len(combined_df)}ê°œ ë°ì´í„°ë¥¼ {CSV_FILE}ì— ì €ì¥ ì™„ë£Œ (ìƒˆë¡œìš´ ë°ì´í„° {len(df)}ê°œ).")
        else:
            # ìƒˆ íŒŒì¼ ìƒì„±
            df = df.sort_values(by="Time", ascending=False)  # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            df.to_csv(CSV_FILE, index=False)
            print(f"ğŸ“‚ ì´ {len(df)}ê°œ ë°ì´í„°ë¥¼ {CSV_FILE}ì— ì €ì¥ ì™„ë£Œ.")

        #convert_csv_to_excel()
    else:
        print("âš ï¸ ì €ì¥í•  ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


def convert_csv_to_excel():
    """CSV íŒŒì¼ì„ ì—‘ì…€ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    df = pd.read_csv(CSV_FILE)

    # 'Time' ì—´ì„ datetimeìœ¼ë¡œ ë³€í™˜í•˜ê³  ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    df['Time'] = pd.to_datetime(df['Time'])
    df = df.sort_values(by="Time", ascending=False)

    excel_filename = CSV_FILE.replace(".csv", ".xlsx")
    df.to_excel(excel_filename, index=False)
    print(f"ğŸ“Š CSV ë°ì´í„°ë¥¼ {excel_filename}ë¡œ ë³€í™˜ ì™„ë£Œ.")


if __name__ == '__main__':
    loop = asyncio.get_event_loop()
    loop.run_until_complete(main())